{
#  d <- df[,c(i, ncol(df))]
d <- d_train[, c(tbl[i,c(1:8)], 9)]
m <- glm(income ~ ., data=d, family = binomial)
prd1 <- (predict(m, newdata=d))
prob <- 1/(1+exp(-prd1))
bestTh <- findBestThold( prob , d$income)
oac[i] <- bestTh[1]
}
#accuracy: 0.8474
time <- proc.time() - time
cat(sprintf("that took %s seconds\n", time))
cat(sprintf("that took %s seconds\n", nuTime))
nuTime <- proc.time() - time
cat(sprintf("that took %s seconds\n", nuTime))
nuTime <- proc.time() - time
cat(sprintf("that took %s seconds\n", nuTime))
nuTime <- proc.time() - time
cat(sprintf("that took %s seconds\n", nuTime))
(mx <- max(oac))                                                    #max(oac)
(setx <- match(mx, oac))                                            #matches max to list
tbl[setx,]
names(d_train)[tbl[setx, c(1, 2, 3, 4, 5, 6, 7, 8)]]                #ID variables of most efficient model
###randomForest Model
#--------------
#load up libraries
suppressMessages(library(randomForest))
#set up function
time <- proc.time()
random_falle <- randomForest(income ~ ., data = d_train, mtry = 4, ntree = 1000)
t
time <- proc.time()
random_falle <- randomForest(income ~ ., data = d_train, mtry = 4, ntree = 1000)
source('~/Desktop/R Projects/navy-2017/script.R')
newTime <- proc.time() - time
cat(sprintf("that took %s seconds\n", newTime))
class(random_falle)                                                 #check function is correct
str(random_falle)                                                   #check structure of function
random_falle$confusion                                              #check confusion martix of function
random_falle$importance                                             #check parameter importance of function
#testing function
irja <- (predict(random_falle, newdata=d_test))                     #predicting new data with model
(tbl_rf <- table(irja, d_test$income))                              #make table with predictions, outcomes
rm(list=ls(
))
time
time =((9/19)*(2*0.2)/(0.06*9.8))
wi = 2
time = ((9/19)*(2*0.2)/(0.06*9.8))
wi = 2
alpha = (10/9)*(0.06*9.8/0.2)
theta = wi*time - (1/2)*alpha*time^2
theta
print(theta)
print(theta/(2*pi))
theta / 2 / pi
rm(list=ls())
I = 3.1
di = 0.87
df = 0.23
wi = 2.2
weight = 3.9
Li = (I + 2*3.9*df^2)*wi
Li = (I + 2*3.9*di^2)*wi
wf = Li/(I + 2*3.9*df^2)
print(wf)
Ii = (I + 2*3.9*di^2)
If = (I + 2*3.9*df^2)
Li = Ii*wi
wf = Li/If
print(wf)
Ki =
Ki = (1/2)*Ii*wi^2
Kf = (1/2)*If*wf^2
dK = Kf - Ki
print(dK)
rm(list=ls())
m = 1.95
vi = 26.9
M = 5.6
l = 2.14
I = (1/12)*M*l^2
Li = m*vi
Li = m*vi*(l/2)
If = I + m*(l/2)
wf = Li/If
print(wf)
If = I + m*(l/2)^2
wf = Li/If
print(wf)
=9.8(.31(1.3+0.016) + .48(.016) + .24(.041))
9.8(.31(1.3+0.016) + .48(.016) + .24(.041))
weight = 9.8(.31(1.3+0.016) + .48(.016) + .24(.041))
weight = 9.8 *( .31* (1.3+0.016) + .48*(.016) + .24*(.041))
print(weight)
string = weight/(.48*sin(arctan(43.5/56)))
string = weight/(.48*sin(tan^-1(43.5/56)))
string = weight/(.48*sin(.6604247397)))
string = weight/(.48*sin(.6604247397))
weight = 9.81 *( .31* (1.3+0.016) + .48*(.016) + .24*(.041))
print(weight)
string = weight/(.48*sin(.6604247397))
print(string)
weight = 9.81 *( .3* (1.3+0.016) + .48*(.016) + .24*(.041))
print(weight)
string = weight/(.48*sin(.6604247397))
print(string)
fx = 14*cos(.6604247397)
weight = 9.81 *( .3* (1.35+0.016) + .48*(.016) + .24*(.041))
print(weight)
string = weight/(.48*sin(.6604247397))
print(string)
fx = string*cos(.6604247397)
fy = g((1.35+0.016) + .016 + 0.041) - string*sin(.6604247397)
fy = 9.81*((1.35+0.016) + .016 + 0.041) - string*sin(.6604247397)
f = sqrt(fx^2 - fy^2)
print(f)
f = sqrt(fx^2 + fy^2)
print(f)
rm(list = ls())
require(ROCR)
findBestThold <- function( predictions, labels, figFileName ){
# pred <- prediction(predictions, testing$good)
pred <- prediction(predictions, labels)
# next apply code from PredictionMetrics.R
perf <- performance(pred,measure="acc",x.measure="cutoff")
# Now let's get the cutoff for the best accuracy
bestAccInd <- which.max(perf@"y.values"[[1]])
bestAccuracy <- round(perf@"y.values"[[1]][bestAccInd], 4)
bestThold <- round(perf@"x.values"[[1]][bestAccInd], 4)
bestMsg <- print(paste("best accuracy=", bestAccuracy,
" at cutoff=", bestThold,
sep=""))
# png( figFileName, width=480, height=480, units="px")   # open PNG file
plot(perf, sub=bestMsg)
# dev.off()
ret <- c(bestAccuracy, bestThold)
ret
}
suppressMessages(library(ggplot2))
suppressMessages(library(caret))
setwd ("/Users/dvmvnds/Desktop/R Projects/")
gummyBears = read.table("stat.txt",
sep=",",header=F,col.names=c("age", "distance"),
fill=FALSE,strip.white=T)
names(gummyBears)
boxplot(distance ~ age, data = gummyBears, main = "Gummy Bear Distance by Angle of Elevation",
xlab = "Angle of Catapult (in number of books)", ylab = "Distance Travelled by Bear (inches)")
axis(side=2, at=seq(0, 300, by = 25))
rm(list = ls())                                                       #clear all
require(ROCR)                                                         #essential package for visualisation
#set destination location
setwd ("/Users/dvmvnds/Desktop/R Projects/")
#essential efficiency function
findBestThold <- function( predictions, labels, figFileName ){
# pred <- prediction(predictions, testing$good)
pred <- prediction(predictions, labels)
# next apply code from PredictionMetrics.R
perf <- performance(pred,measure="acc",x.measure="cutoff")
# Now let's get the cutoff for the best accuracy
bestAccInd <- which.max(perf@"y.values"[[1]])
bestAccuracy <- round(perf@"y.values"[[1]][bestAccInd], 4)
bestThold <- round(perf@"x.values"[[1]][bestAccInd], 4)
bestMsg <- print(paste("best accuracy=", bestAccuracy,
" at cutoff=", bestThold,
sep=""))
# png( figFileName, width=480, height=480, units="px")   # open PNG file
plot(perf, sub=bestMsg)
# dev.off()
ret <- c(bestAccuracy, bestThold)
ret
}
#read data
forvara = read.table("adult.data.txt",
sep=",",header=F,col.names=c("age", "type_employer", "fnlwgt", "education",
"education_num","marital", "occupation", "relationship", "race","sex",
"capital_gain", "capital_loss", "hr_per_week","country", "income"),
fill=FALSE,strip.white=T)
maena = read.table("adult.test.txt",
sep=",",header=F,col.names=c("age", "type_employer", "fnlwgt", "education",
"education_num","marital", "occupation", "relationship", "race","sex",
"capital_gain", "capital_loss", "hr_per_week","country", "income"),
fill=FALSE,strip.white=T)
#combine data
totaldata <- rbind(forvara, maena)
#split data into training, testing sets
idx <- c(1:32561)
d_train <- totaldata[idx,]
d_test <- totaldata[-idx,]
###Logistic Regression Model
#--------------
#load up libraries
suppressMessages(library(ggplot2))
suppressMessages(library(caret))
suppressMessages(library(arm))
suppressMessages(library(plyr))
#eliminate non-essential parameters
d_train$capital_loss <- NULL
d_train$fnlwgt <- NULL
d_train$age <- NULL
d_train$marital <- NULL
d_train$hr_per_week <- NULL
d_train$country <- NULL
#check correctness of training data
str(d_train)                                                         #check structure of training data
names(d_train)                                                       #check headers of training data
#Set up table of all permutations
#this is really stupid but i'll fix it later when i'm cleaning up
tbl1 <- gtools::combinations(8, 1)
tbl2 <- gtools::combinations(8, 2)
tbl3 <- gtools::combinations(8, 3)
tbl4 <- gtools::combinations(8, 4)
tbl5 <- gtools::combinations(8, 5)
tbl6 <- gtools::combinations(8, 6)
tbl7 <- gtools::combinations(8, 7)
tbl8 <- gtools::combinations(8, 8)
valje <- rbind.fill.matrix(tbl1, tbl2, tbl3, tbl4, tbl5, tbl6, tbl7, tbl8)
tbl <- matrix(valje, 255, 8)
tbl[is.na(tbl)] = 0
N=255
oac <- rep(0,N)
time <- proc.time()
for (i in 1:N)
{
#  d <- df[,c(i, ncol(df))]
d <- d_train[, c(tbl[i,c(1:8)], 9)]
m <- glm(income ~ ., data=d, family = binomial)
prd1 <- (predict(m, newdata=d))
prob <- 1/(1+exp(-prd1))
bestTh <- findBestThold( prob , d$income)
oac[i] <- bestTh[1]
}
source('~/Desktop/R Projects/navy-2017/script.R')
rm(list = ls())                                                       #clear all
require(ROCR)                                                         #essential package for visualisation
#set destination location
setwd ("/Users/dvmvnds/Desktop/R Projects/")
#essential efficiency function
findBestThold <- function( predictions, labels, figFileName ){
# pred <- prediction(predictions, testing$good)
pred <- prediction(predictions, labels)
# next apply code from PredictionMetrics.R
perf <- performance(pred,measure="acc",x.measure="cutoff")
# Now let's get the cutoff for the best accuracy
bestAccInd <- which.max(perf@"y.values"[[1]])
bestAccuracy <- round(perf@"y.values"[[1]][bestAccInd], 4)
bestThold <- round(perf@"x.values"[[1]][bestAccInd], 4)
bestMsg <- print(paste("best accuracy=", bestAccuracy,
" at cutoff=", bestThold,
sep=""))
# png( figFileName, width=480, height=480, units="px")   # open PNG file
plot(perf, sub=bestMsg)
# dev.off()
ret <- c(bestAccuracy, bestThold)
ret
}
#read data
forvara = read.table("adult.data.txt",
sep=",",header=F,col.names=c("age", "type_employer", "fnlwgt", "education",
"education_num","marital", "occupation", "relationship", "race","sex",
"capital_gain", "capital_loss", "hr_per_week","country", "income"),
fill=FALSE,strip.white=T)
maena = read.table("adult.test.txt",
sep=",",header=F,col.names=c("age", "type_employer", "fnlwgt", "education",
"education_num","marital", "occupation", "relationship", "race","sex",
"capital_gain", "capital_loss", "hr_per_week","country", "income"),
fill=FALSE,strip.white=T)
#combine data
totaldata <- rbind(forvara, maena)
#split data into training, testing sets
idx <- c(1:32561)
d_train <- totaldata[idx,]
d_test <- totaldata[-idx,]
###Logistic Regression Model
#--------------
#load up libraries
suppressMessages(library(ggplot2))
suppressMessages(library(caret))
suppressMessages(library(arm))
suppressMessages(library(plyr))
#eliminate non-essential parameters
d_train$capital_loss <- NULL
d_train$fnlwgt <- NULL
d_train$age <- NULL
d_train$marital <- NULL
d_train$hr_per_week <- NULL
d_train$country <- NULL
#check correctness of training data
str(d_train)                                                         #check structure of training data
names(d_train)                                                       #check headers of training data
#Set up table of all permutations
#this is really stupid but i'll fix it later when i'm cleaning up
tbl1 <- gtools::combinations(8, 1)
tbl2 <- gtools::combinations(8, 2)
tbl3 <- gtools::combinations(8, 3)
tbl4 <- gtools::combinations(8, 4)
tbl5 <- gtools::combinations(8, 5)
tbl6 <- gtools::combinations(8, 6)
tbl7 <- gtools::combinations(8, 7)
tbl8 <- gtools::combinations(8, 8)
valje <- rbind.fill.matrix(tbl1, tbl2, tbl3, tbl4, tbl5, tbl6, tbl7, tbl8)
tbl <- matrix(valje, 255, 8)
tbl[is.na(tbl)] = 0
N=255
oac <- rep(0,N)
time <- proc.time()
for (i in 1:N)
{
#  d <- df[,c(i, ncol(df))]
d <- d_train[, c(tbl[i,c(1:8)], 9)]
m <- glm(income ~ ., data=d, family = binomial)
prd1 <- (predict(m, newdata=d))
prob <- 1/(1+exp(-prd1))
bestTh <- findBestThold( prob , d$income)
oac[i] <- bestTh[1]
}
molH2 <- 0.975/(0.0821*298)
n1 <- 0.0592/2
n2 <- 0.192 - 0.402
print(n2 / n1)
Math.pow(7.094595, 10)
print(7.094595 ^ 10)
print(.9 * 0.3985 / (323054716 ^ 2))
print(.9 * 0.3985 / (323054716 ^ 2))
print(3.436518e-18 ^ .5)
print(-log(1.853785e-09))
log(1.853785e-09)
rm(list = ls())
m_h2 <- 0.975 / (298 * 0.0821)
m_cd2+ <- 0.9
m_h2 <- 0.975 / (298 * 0.0821)
m_cd2 <- 0.9
m_h2 <- 0.975 / (298 * 0.0821)
eCell <- 0.192
n <- 2
E0 <- 0.402
n <- 2
m_cd2 <- 0.9
m_h2 <- 0.975 / (298 * 0.0821)
Ecell <- 0.192
E0 <- 0.402
n <- 2
rm(eCell)
# Ecell = E0 - 0.0592/n * log(Q)
logQ <- (Ecell - E0) * n / 0.0592
NERNST_CONST <- 0.0592
logQ <- (Ecell - E0) * n / NERNST_CONST
logQ <- (Ecell - E0) * n / -NERNST_CONST
Q <- 10 ^ logQ
# Q = [Cd2+][H2]/[H]^2
H <- sqrt(m_cd2 * m_h2 / Q)
pH <- log10(H)
pH <- -log10(H)
# Q = [Cd2+][H2]/[H+]^2
# [H+] = sqrt([Cd2+][H2] / Q)
H <- sqrt(m_cd2 * m_h2 / Q)
# pH = -log(H+)
pH <- -log10(H)
H <- sqrt(m_cd2 * m_h2 / Q /4)
# pH = -log(H+)
pH <- -log10(H)
H <- sqrt(m_cd2 * m_h2 / Q)
# pH = -log(H+)
pH <- -log10(H)
pH <- -log10(H)
H <- sqrt(m_cd2 * m_h2 / Q) /2
# pH = -log(H+)
pH <- -log10(H)
H <- sqrt(m_cd2 * m_h2 / Q)
# pH = -log(H+)
pH <- -log10(H)
Q
rm(list = ls())                                                       #clear all
require(ROCR)                                                         #essential package for visualisation
#set destination location
setwd ("/Users/dvmvnds/Desktop/R Projects/")
#essential efficiency function
findBestThold <- function( predictions, labels, figFileName ){
# pred <- prediction(predictions, testing$good)
pred <- prediction(predictions, labels)
# next apply code from PredictionMetrics.R
perf <- performance(pred,measure="acc",x.measure="cutoff")
# Now let's get the cutoff for the best accuracy
bestAccInd <- which.max(perf@"y.values"[[1]])
bestAccuracy <- round(perf@"y.values"[[1]][bestAccInd], 4)
bestThold <- round(perf@"x.values"[[1]][bestAccInd], 4)
bestMsg <- print(paste("best accuracy=", bestAccuracy,
m_cd2 <- 0.9
m_h2 <- 0.975 / (298 * 0.0821)
Ecell <- 0.192
E0 <- 0.402
n <- 2
NERNST_CONST <- 0.0592
logQ <- (Ecell - E0) * n / -NERNST_CONST
Q <- 10 ^ logQ
H <- sqrt(m_cd2 * m_h2 / Q)
pH <- -log10(H)
(0.1 * 221 + 0.25 * (180 + 28)) * 1.35
(0.1 * 221 + 0.25 * (208)) * 1.35
(0.1 * 221 + 0.25 * (208)) * 1.35
(0.1 * 2 * 221 + 0.25 * (208)) * 1.35
16 * 0.1 + 17 * .3 + 18 * .4 + 19 * .2
EcJ <- 16 * 0.1 + 17 * .3 + 18 * .4 + 19 * .2
EcC <- 17 * 0.45 + 18 * 0.4 + 19 * .15
.1 * .45
.3(.4)
.3*.4
.4*.15
.1 * .45 +
.3*.4 +
.4*.15
1-.015-.225-.325-.26-.09
.015+.225+.085
Math.sqrt(.77*.23/40)
sqrt(.77*.23/40)
# image_processing.R
# http://r.789695.n4.nabble.com/Loading-an-image-picture-png-jpeg-to-screen-td2244923.html
# 2017, April, 21
library(gridExtra)
install.packages("EBImage")
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
library(gridExtra)
install.packages("EBImage")
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
library(EBImage)
install.packages("RGraphics")
library(RGraphics)
x <- readImage("http://www.google.com/logos/teachersday09.gif")
g1 <- ebimageGrob(x)
dev.new(width=g1$width, height=g1$height)
grid.draw(g1)
BiocStyle::markdown()
rm(list=ls())
library("EBImage")
f = system.file("images", "sample.png", package="EBImage")
img = readImage(f)
display(img)
img
install.packages('shiny')
library('shiny')
runExample('01_hello')
runApp('SVD')
runApp('SVD')
system.file("images", "sample.png", package="EBImage")
runApp('SVD')
system.file("/", "sample.png"))
system.file("/", "sample.png", ""))
runApp('SVD')
runApp('SVD')
runApp('SVD')
runApp('SVD')
f = 'sample.png'
img = readImage(f)
readImage('sample.png')
image(readImage('sample.png'))
runApp('SVD')
runApp('SVD')
runApp('SVD')
runApp('SVD')
runApp('SVD')
runApp('SVD')
library(shiny)
library("EBImage")
flip(readImage('sample.png'))
runApp('SVD')
!file.exists('http://www.penguins-world.com/wp-content/uploads/Emperor_penguins.jpg')
file.exists('http://www.penguins-world.com/wp-content/uploads/Emperor_penguins.jpg')
file.exists('http://www.penguins-world.com/wp-content/uploads/')
runApp('SVD')
runApp('SVD')
rm(list=ls())
library("EBImage")
f = system.file("images", "sample.png", package="EBImage")
img = readImage(f)
display(img)
dim(img)
res <- svd(img)
d=res[[1]]
D=diag(d)
U=res[[2]]
dim(U) # 768 512
V=res[[3]]
dim(V)
tV = t(V)
img_rc = U%*%D%*%tV
display(img_rc)
K=50
apx_img = matrix( rep(0, 768*512), ncol=512)
for (i in 1:K) {
apx_img = apx_img + d[i]*matrix(U[,i], ncol=1)%*%tV[i,]
}
display(apx_img)
View(apx_img)
runApp('SVD')
runApp('SVD')
runApp('SVD')
install.packages('rsconnect')
rsconnect::setAccountInfo(name='ayaz',
token='68669FCAE82F4D5880F5D57A872981F4',
secret='NZc7SjmCpefKzpd6xafbl8oAxRv0qlQdahFL9bmU')
rsconnect::deployApp('SVD')
rsconnect::deployApp('svd-image')
require("EBImage")
install.packages(EBImage)
install.packages('EBImage')
install.packages("EBImage")
rsconnect::deployApp('svd-image')
rsconnect::deployApp('svd-image')
packrat:::appDependencies()
runApp('svd-image')
